{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700995b8-250a-4481-995d-eaf308c8b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import os\n",
    "import re\n",
    "import sympy as sp\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "\n",
    "# âœ… Load API key\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.Client(api_key=API_KEY)\n",
    "\n",
    "# âœ… Read math500 dataset\n",
    "def load_jsonl(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "data = load_jsonl(\"math500.jsonl\")\n",
    "\n",
    "# âœ… Cleaning and extraction functions\n",
    "def balance_braces(expr):\n",
    "    open_count = expr.count(\"{\")\n",
    "    close_count = expr.count(\"}\")\n",
    "    if close_count < open_count:\n",
    "        expr += \"}\" * (open_count - close_count)\n",
    "    return expr\n",
    "\n",
    "def extract_boxed(expr):\n",
    "    start = expr.find(r\"\\boxed{\")\n",
    "    if start == -1:\n",
    "        return expr.strip()\n",
    "    i = start + len(r\"\\boxed{\")\n",
    "    brace_count = 1\n",
    "    content = \"\"\n",
    "    while i < len(expr) and brace_count > 0:\n",
    "        if expr[i] == \"{\":\n",
    "            brace_count += 1\n",
    "        elif expr[i] == \"}\":\n",
    "            brace_count -= 1\n",
    "        content += expr[i]\n",
    "        i += 1\n",
    "    if brace_count != 0:\n",
    "        return \"âŒ Invalid: Unmatched braces\"\n",
    "    content = content[:-1] if content.endswith(\"}\") else content\n",
    "    content = balance_braces(content)\n",
    "    if re.fullmatch(r\"\\\\frac\\{[^{}]+\\}\", content):\n",
    "        return \"âŒ Invalid: Incomplete \\\\frac\"\n",
    "    return content.strip()\n",
    "\n",
    "def clean_latex(expr):\n",
    "    expr = expr.replace(\" \", \"\").replace(\"\\\\left\", \"\").replace(\"\\\\right\", \"\")\n",
    "    expr = expr.replace(\"^\\\\circ\", \"\").replace(\"\\\\\\\\\", \"\\\\\")\n",
    "    expr = re.sub(r\"\\\\sqrt([a-zA-Z0-9])\", r\"\\\\sqrt{\\1}\", expr)\n",
    "    expr = re.sub(r\"\\\\frac([0-9])([0-9])\", r\"\\\\frac{\\1}{\\2}\", expr)\n",
    "    return expr\n",
    "\n",
    "def is_valid_latex_fraction(expr):\n",
    "    return not bool(re.search(r\"\\\\frac\\{[^{}]+\\}(?!\\{)\", expr))\n",
    "\n",
    "def is_equivalent(expr1, expr2):\n",
    "    expr1 = clean_latex(expr1)\n",
    "    expr2 = clean_latex(expr2)\n",
    "    if \"\\\\text\" in expr1 or \"\\\\text\" in expr2:\n",
    "        return expr1 == expr2\n",
    "    try:\n",
    "        a = sp.simplify(sp.sympify(expr1))\n",
    "        b = sp.simplify(sp.sympify(expr2))\n",
    "        return sp.simplify(a - b) == 0\n",
    "    except Exception:\n",
    "        return expr1 == expr2\n",
    "\n",
    "# âœ… GPT call\n",
    "def solve_problem(prompt):\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            max_tokens=100,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are a statistics master student.\n",
    "\n",
    "Your task:\n",
    "- Solve the math problem below.\n",
    "- Only return the **final answer** in LaTeX, wrapped inside \\boxed{...}.\n",
    "- DO NOT output any explanation, steps, or reasoning.\n",
    "- If you cannot solve the problem, return \\boxed{?}.\n",
    "- Your output must be a single valid \\boxed{...} expression â€” nothing else.\n",
    "\n",
    "Example of valid output: \\boxed{\\frac{1}{2}}\"\"\"}, \n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        raw = response.choices[0].message.content.strip()\n",
    "        return extract_boxed(raw)\n",
    "    except Exception as e:\n",
    "        return f\"âŒ API Error: {str(e)}\"\n",
    "\n",
    "# âœ… Main evaluation logic\n",
    "N = 500  # Adjustable: number of problems to evaluate\n",
    "correct = 0\n",
    "evaluated = 0\n",
    "\n",
    "level_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "subject_stats = defaultdict(lambda: {\"correct\": 0, \"total\": 0})\n",
    "\n",
    "print(\"\\n====== âŒ Incorrect Answers ======\\n\")\n",
    "\n",
    "for i in range(N):\n",
    "    item = data[i]\n",
    "    q = item[\"problem\"]\n",
    "    ref = clean_latex(item[\"answer\"])\n",
    "    level = item.get(\"level\", \"unknown\")\n",
    "    subject = item.get(\"subject\", \"unknown\")\n",
    "\n",
    "    pred_raw = solve_problem(q)\n",
    "    pred = clean_latex(pred_raw)\n",
    "\n",
    "    if \"âŒ\" in pred_raw or not is_valid_latex_fraction(pred):\n",
    "        continue  # Skip malformed outputs\n",
    "\n",
    "    evaluated += 1\n",
    "    level_stats[level][\"total\"] += 1\n",
    "    subject_stats[subject][\"total\"] += 1\n",
    "\n",
    "    if is_equivalent(pred, ref):\n",
    "        correct += 1\n",
    "        level_stats[level][\"correct\"] += 1\n",
    "        subject_stats[subject][\"correct\"] += 1\n",
    "    else:\n",
    "        print(f\"âŒ Question {i+1} incorrect\")\n",
    "        print(f\"âœ… Correct answer: {ref}\")\n",
    "        print(f\"âŒ GPT generated: {pred}\\n\")\n",
    "\n",
    "# âœ… Print total accuracy\n",
    "accuracy = 100 * correct / evaluated if evaluated > 0 else 0\n",
    "print(f\"âœ… Total correct: {correct} / {evaluated}\")\n",
    "print(f\"âœ… GPT-4o total accuracy: {accuracy:.2f}%\\n\")\n",
    "\n",
    "# âœ… Print accuracy breakdown\n",
    "def print_accuracy(title, stats):\n",
    "    print(f\"ðŸ“Š {title} Accuracy:\")\n",
    "    for key, v in sorted(stats.items()):\n",
    "        acc = 100 * v[\"correct\"] / v[\"total\"] if v[\"total\"] > 0 else 0.0\n",
    "        print(f\" - {key}: {acc:.2f}%\")\n",
    "    print()\n",
    "\n",
    "print_accuracy(\"Level-wise\", level_stats)\n",
    "print_accuracy(\"Subject-wise\", subject_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2950e14-2cc3-42c1-b27d-5f9776a58818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
